(DataSize=nrow(zillow_DT_df))
(TrainingSet_Size<-floor(DataSize*(3/4))) ## Size for training set
(TestSet_Size <- DataSize - TrainingSet_Size) ## Size for testing set
set.seed(2021)
## training sample
MyTrainSample <- sample(nrow(zillow_DT_df),
TrainingSet_Size,replace=FALSE)
MyTrainingSET <- zillow_DT_df[MyTrainSample,]
table(MyTrainingSET$label)
## test sample
MyTestSET <- zillow_DT_df[-MyTrainSample,]
table(MyTestSET$label)
# remove label
TestKnownLabels <- MyTestSET$label
MyTestSET <- MyTestSET[ , -which(names(MyTestSET) %in% c("label"))]
#################################
#################################
## Decision Trees
#################################
MyTrainingSET
str(MyTrainingSET)
## tree 1
DT <- rpart(MyTrainingSET$label ~ ., data = MyTrainingSET, method="class")
summary(DT)
# visualization
rpart.plot(DT,cex=0.5,under = TRUE)
(DataSize=nrow(zillow_DT_df_1))
(TrainingSet_Size<-floor(DataSize*(3/4))) ## Size for training set
(TestSet_Size <- DataSize - TrainingSet_Size) ## Size for testing set
set.seed(2021)
## training sample
MyTrainSample <- sample(nrow(zillow_DT_df_1),
TrainingSet_Size,replace=FALSE)
MyTrainingSET <- zillow_DT_df_1[MyTrainSample,]
table(MyTrainingSET$label)
## test sample
MyTestSET <- zillow_DT_df_1[-MyTrainSample,]
table(MyTestSET$label)
# remove label
TestKnownLabels <- MyTestSET$label
MyTestSET <- MyTestSET[ , -which(names(MyTestSET) %in% c("label"))]
MyTrainingSET
str(MyTrainingSET)
## tree 1
DT <- rpart(MyTrainingSET$label ~ ., data = MyTrainingSET, method="class")
summary(DT)
# visualization
rpart.plot(DT,cex=0.5,under = TRUE)
# testing data
(DT_Prediction= predict(DT, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction,TestKnownLabels)
barplot(DT$variable.importance)
barplot(DT$variable.importance,col=rgb(0.2,0.4,0.6,0.6))
library(RColorBrewer)
coul <- brewer.pal(5, "Set2")
barplot(DT$variable.importance,col=coul)
barplot(DT$variable.importance,col=coul,ylab="Importance")
barplot(DT$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 1")
## tree 2
DT2<-rpart(MyTrainingSET$label ~ .,
data = MyTrainingSET,method="class",
parms = list(split = 'information'))
summary(DT2)
rpart.plot(DT2,cex=0.5,under = TRUE)
# testing data
(DT_Prediction2= predict(DT2, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction2,TestKnownLabels)
barplot(DT2$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 1")
barplot(DT2$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 2")
## tree 3
DT3<-rpart(MyTrainingSET$label ~ X2020+X2019+X2018,
data = MyTrainingSET,method="class")
summary(DT3)
rpart.plot(DT3,cex=0.5,under = TRUE)
# testing data
(DT_Prediction3= predict(DT3, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction3,TestKnownLabels)
barplot(DT3$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 3")
rpart.plot(DT2,cex=0.5,under = TRUE)
# visualization
rpart.plot(DT,cex=0.5,under = TRUE)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE)
rpart.plot(DT2,cex=0.7,under = TRUE)
barplot(DT$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 1", main = "Tree 1")
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1")
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space = 0))
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space = 0)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space = 0, tweak = 0.8)
# visualization
rpart.plot(DT,under = TRUE,main = "Tree 1",space = 0, tweak = 0.8)
# visualization
rpart.plot(DT,under = TRUE,main = "Tree 1",space = 0, tweak = 1.8)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space = 0)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",uniform=FALSE)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1")
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=0)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=1)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=0,Margin=1)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=0,Margin=0.1)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=0,gap=0.1)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=0,gap=0.2)
rpart.plot(DT2,cex=0.7,under = TRUE,main = "Tree 2",space=0,gap=0.2)
rpart.plot(DT3,cex=0.5,under = TRUE,main = "Tree 3",space=0,gap=0.2)
## Confusion Matrix
table(DT_Prediction,TestKnownLabels)
## Confusion Matrix
table(DT_Prediction2,TestKnownLabels)
## Confusion Matrix
table(DT_Prediction3,TestKnownLabels)
zillow_DT_df_2 <- zillow_DT_df[,-1]
# remove state
zillow_DT_df_2 <- zillow_DT_df_2[,-1]
str(zillow_DT_df_1)
colnames(zillow_DT_df_2$label) <- "home_type"
colnames(zillow_DT_df_2[,label]) <- "home_type"
colnames(zillow_DT_df_2[4]) <- "home_type"
str(zillow_DT_df_1)
colnames(zillow_DT_df_2)[4] <- "home_type"
str(zillow_DT_df_1)
str(zillow_DT_df_2)
head(zillow_DT_df_2)
(DataSize=nrow(zillow_DT_df_2))
(TrainingSet_Size<-floor(DataSize*(3/4))) ## Size for training set
(TestSet_Size <- DataSize - TrainingSet_Size) ## Size for testing set
set.seed(2021)
## training sample
MyTrainSample <- sample(nrow(zillow_DT_df_2),
TrainingSet_Size,replace=FALSE)
MyTrainingSET <- zillow_DT_df_2[MyTrainSample,]
table(MyTrainingSET$USregion)
## test sample
MyTestSET <- zillow_DT_df_2[-MyTrainSample,]
table(MyTestSET$USregion)
# remove label
TestKnownLabels <- MyTestSET$USregion
MyTestSET <- MyTestSET[ , -which(names(MyTestSET) %in% c("USregion"))]
DT <- rpart(MyTrainingSET$USregion ~ ., data = MyTrainingSET, method="class")
summary(DT)
# visualization
rpart.plot(DT,cex=0.5,under = TRUE)
(DT_Prediction= predict(DT, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction,TestKnownLabels)
barplot(DT$variable.importance)
DT2<-rpart(MyTrainingSET$USregion ~ .,
data = MyTrainingSET,method="class",
parms = list(split = 'information'))
summary(DT2)
rpart.plot(DT2,cex=0.5,under = TRUE)
# testing data
(DT_Prediction2= predict(DT2, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction2,TestKnownLabels)
barplot(DT2$variable.importance)
DT3<-rpart(MyTrainingSET$USregion ~ X2020+X2019+X2018,
data = MyTrainingSET,method="class")
summary(DT3)
rpart.plot(DT3,cex=0.5,under = TRUE)
# testing data
(DT_Prediction3= predict(DT3, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction3,TestKnownLabels)
barplot(DT3$variable.importance)
## tree 1
DT <- rpart(MyTrainingSET$USregion ~ ., data = MyTrainingSET, method="class")
summary(DT)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=0,gap=0.2)
# testing data
(DT_Prediction= predict(DT, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction,TestKnownLabels)
barplot(DT$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 1")
str(MyTrainingSET)
DT <- rpart(MyTrainingSET$USregion ~ ., data = MyTrainingSET, method="class")
summary(DT)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=0,gap=0.2)
DT <- rpart(MyTrainingSET$USregion ~ X2018+X2019+X2020+home_type+type, data = MyTrainingSET, method="class")
summary(DT)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=0,gap=0.2)
# testing data
(DT_Prediction= predict(DT, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction,TestKnownLabels)
barplot(DT$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 1")
DT <- rpart(MyTrainingSET$USregion ~ ., data = MyTrainingSET, method="class")
summary(DT)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=0,gap=0.2)
# visualization
rpart.plot(DT,cex=1,under = TRUE,main = "Tree 1",space=0,gap=0.2)
# visualization
rpart.plot(DT,cex=0.7,under = TRUE,main = "Tree 1",space=0,gap=0.2)
# visualization
rpart.plot(DT,cex=0.7,under = FALSE,main = "Tree 1",space=0,gap=0.2)
# visualization
rpart.plot(DT,cex=0.7,under = FALSE,main = "Tree 1",space=0,gap=0.2,fallen.leaves=TRUE)
# visualization
rpart.plot(DT,cex=0.7,under = FALSE,main = "Tree 1",space=0,gap=0.2,uniform=FALSE)
# visualization
rpart.plot(DT,cex=0.7,main = "Tree 1",space=0,gap=0.2,type = 0)
# visualization
rpart.plot(DT,cex=0.7,main = "Tree 1",space=0,gap=0.2,type = 4)
# visualization
rpart.plot(DT,cex=0.7,main = "Tree 1",space=0,gap=0.2,type = 3)
# visualization
rpart.plot(DT,cex=0.7,main = "Tree 1",space=0,gap=0.2)
# visualization
rpart.plot(DT,cex=0.7,under=TRUE,main = "Tree 1",space=0,gap=0.2)
(DT_Prediction= predict(DT, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction,TestKnownLabels)
barplot(DT$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 1")
DT2<-rpart(MyTrainingSET$USregion ~ .,
data = MyTrainingSET,method="class",
parms = list(split = 'information'))
summary(DT2)
rpart.plot(DT2,cex=0.7,under = TRUE,main = "Tree 2",space=0,gap=0.2)
(DT_Prediction2= predict(DT2, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction2,TestKnownLabels)
barplot(DT2$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 2")
DT3<-rpart(MyTrainingSET$USregion ~ X2020+X2019+X2018,
data = MyTrainingSET,method="class")
summary(DT3)
rpart.plot(DT3,cex=0.5,under = TRUE,main = "Tree 3",space=0,gap=0.2)
(DT_Prediction3= predict(DT3, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction3,TestKnownLabels)
barplot(DT3$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 3")
filename="Twitter_API_keys.txt"
(tokens<-read.csv(filename, header=TRUE, sep=","))
(consumerKey=as.character(tokens$consumerKey))
consumerSecret=as.character(tokens$consumerSecret)
access_Token=as.character(tokens$access_Token)
access_Secret=as.character(tokens$access_Secret)
requestURL='https://api.twitter.com/oauth/request_token'
accessURL='https://api.twitter.com/oauth/access_token'
authURL='https://api.twitter.com/oauth/authorize'
setup_twitter_oauth(consumerKey,consumerSecret,access_Token,access_Secret)
token <- create_token(
consumer_key = consumerKey,
consumer_secret = consumerSecret,
access_token = access_Token,
access_secret = access_Secret)
## seach and eliminate retweets
Search1<-search_tweets("#homebuying -filter:retweets",n=5000, lang = "en",
include_rts = FALSE, token=token)
library(rtweet)
library(twitteR)
library(ROAuth)
library(jsonlite)
library(tokenizers)
library(stopwords)
library(tm)
library(arules)
## read my API keys
## users should have their own keys
filename="Twitter_API_keys.txt"
(tokens<-read.csv(filename, header=TRUE, sep=","))
(consumerKey=as.character(tokens$consumerKey))
consumerSecret=as.character(tokens$consumerSecret)
access_Token=as.character(tokens$access_Token)
access_Secret=as.character(tokens$access_Secret)
requestURL='https://api.twitter.com/oauth/request_token'
accessURL='https://api.twitter.com/oauth/access_token'
authURL='https://api.twitter.com/oauth/authorize'
setup_twitter_oauth(consumerKey,consumerSecret,access_Token,access_Secret)
token <- create_token(
consumer_key = consumerKey,
consumer_secret = consumerSecret,
access_token = access_Token,
access_secret = access_Secret)
## seach and eliminate retweets
Search1<-search_tweets("#homebuying -filter:retweets",n=5000, lang = "en",
include_rts = FALSE, token=token)
head(Search_text)
Search_text <- Search1$text
head(Search_text)
library(randomForest)
install.packages("randomForest")
library(randomForest)
library(randomForest)
MyTrainingSET
rf <- randomForest(
USregion ~ .,
data=MyTrainingSET
)
## prediction
pred = predict(rf, newdata=MyTestSET[-6])
# confusion matrix
cm = table(test[,14], pred)
rf <- randomForest(
USregion ~ .,
data=MyTrainingSET
)
## prediction
pred = predict(rf, newdata=MyTestSET[-6])
# confusion matrix
cm = table(MyTestSET[,6], pred)
MyTestSET[,6]
MyTestSET[,5]
MyTestSET
# confusion matrix
cm = table(TestKnownLabels, pred)
# confusion matrix
(cm = table(TestKnownLabels, pred))
install.packages("reprtree")
library(reprtree)
install.packages("devtools")
library(devtools)
devtools::install_github('araastat/reprtree')
library(reprtree)
# visualization
reprtree:::plot.getTree(rf)
# visualization
reprtree:::plot.reprtree(rf)
ggplot(as.data.frame(cm),
aes(x=pred, y=TestKnownLabels, fill=Freq)) +
geom_tile() +
scale_fill_gradient(low = "white", high = "steelblue")+
geom_text(aes(label=Freq))
rf$importance  ## Includes GINI
class(rf)
class(rf$importance)
## Feature importance
imp <- as.data.frame(rf$importance)
imp
## Feature importance
imp <- as.data.frame(rf$importance,keep.rownames = TRUE)
imp
## Feature importance
imp <- as.data.frame(rf$importance,keep.rownames = FALSE)
## Feature importance
imp <- data.frame(columnNameILike = row.names(rf$importance), rf$importance)
imp
## Feature importance
imp <- data.frame(feature = row.names(rf$importance), rf$importance)
ggplot(data = imp,aes(y=feature))+
geom_bar()  ## Includes GINI
ggplot(data = imp,aes(x=feature,y=MeanDecreaseGini))+
geom_bar()  ## Includes GINI
imp$MeanDecreaseGini
ggplot(data = imp,aes(y=MeanDecreaseGini))+
geom_bar()  ## Includes GINI
ggplot(data = imp,aes(x=feature,y=MeanDecreaseGini))+
geom_bar(stat="identity")  ## Includes GINI
ggplot(data = imp,aes(x=x = reorder(feature, -MeanDecreaseGini),y=MeanDecreaseGini))+
geom_bar(stat="identity")  ## Includes GINI
ggplot(data = imp,aes(x = reorder(feature, -MeanDecreaseGini),y=MeanDecreaseGini))+
geom_bar(stat="identity")  ## Includes GINI
# visualization
reprtree:::plot.reprtree(rf)
ggplot(data = imp,aes(x = reorder(feature, -MeanDecreaseGini),
y=MeanDecreaseGini, fill = feature))+
geom_bar(stat="identity")+
ggtitle("Random Forest Feature Importance") +
xlab("Feature") + ylab("Mean Decrease Gini")
table(MyTrainingSET$label)
setwd("~/Desktop/GU/ANLY501/portfolio/data")
zillow_DT_df <- read.csv("zillow_DT_df.csv",stringsAsFactors=TRUE)
str(zillow_DT_df)
head(zillow_DT_df)
# remove region column
zillow_DT_df_2 <- zillow_DT_df[,-1]
# remove state
zillow_DT_df_2 <- zillow_DT_df_2[,-1]
colnames(zillow_DT_df_2)[4] <- "home_type"
str(zillow_DT_df_2)
head(zillow_DT_df_2)
(DataSize=nrow(zillow_DT_df_2))
(TrainingSet_Size<-floor(DataSize*(3/4))) ## Size for training set
(TestSet_Size <- DataSize - TrainingSet_Size) ## Size for testing set
set.seed(2021)
## training sample
MyTrainSample <- sample(nrow(zillow_DT_df_2),
TrainingSet_Size,replace=FALSE)
MyTrainingSET <- zillow_DT_df_2[MyTrainSample,]
table(MyTrainingSET$USregion)
91/362
MyTestSET <- zillow_DT_df_2[-MyTrainSample,]
table(MyTestSET$USregion)
table(MyTrainingSET)
table(MyTrainingSET$home_type,MyTrainingSET$type,MyTrainingSET$USregion)
DT2<-rpart(MyTrainingSET$USregion ~ .,
data = MyTrainingSET,method="class",
parms = list(split = 'information'))
summary(DT2)
rpart.plot(DT2,cex=0.7,under = TRUE,main = "Tree 2",space=0,gap=0.2)
# testing data
(DT_Prediction2= predict(DT2, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction2,TestKnownLabels)
barplot(DT2$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 2")
DT3<-rpart(MyTrainingSET$USregion ~ X2020+X2019+X2018,
data = MyTrainingSET,method="class")
summary(DT3)
rpart.plot(DT3,cex=0.5,under = TRUE,main = "Tree 3",space=0,gap=0.2)
# testing data
(DT_Prediction3= predict(DT3, MyTestSET, type="class"))
## Confusion Matrix
table(DT_Prediction3,TestKnownLabels)
barplot(DT3$variable.importance,col=coul,ylab="Importance",
main = "Variable importance of Tree 3")
```{r}
library(ISLR)
```
install.packages("ISLR")
```{r}
library(ISLR)
```
library(ISLR)
Auto
knitr::opts_chunk$set(echo = TRUE,
fig.width = 6,
fig.asp = 0.8,
out.width = "80%")
library(ISLR)
pairs(Auto, pch = 19)
cor(Auto[-9])
df_lm <- Auto[-9]
summary(lm(mpg~., df_lm))
df_lm <- Auto[-9]
model <- lm(mpg~., df_lm)
summary(model)
model$effects
model$qr
model$assign
test <- summary(model)
model$coefficients
model$coefficients["year"]
model$coefficients[["year"]]
model2 <- lm(mpg~(.)^2, df_lm)
(smry2 <- summary(model2))
## log(X)
model3 <- lm(mpg~log(.), df_lm)
df_lm2 <- data.frame(log10(df_lm[-"mpg"]),df_lm["mpg"])
df_lm2 <- data.frame(log10(df_lm[-"mpg"]),df_lm$mpg)
log10(df_lm[-"mpg"])
log10(df_lm[,-"mpg"])
df_lm["mpg"]
log10(subset(df_lm, select = "mpg"))
subset(df_lm, select = -"mpg"))
subset(df_lm, select = -"mpg")
log10(subset(df_lm, select = -("mpg"))
)
log10(subset(df_lm, select = -c("mpg")))
log10(subset(df_lm, select = -mpg))
## log(X)
df_lm2 <- data.frame(log10(subset(df_lm, select = -mpg)),df_lm["mpg"])
model3 <- lm(mpg~., df_lm2)
(smry3 <- summary(model3))
## sqrt(X)
df_lm3 <- data.frame(sqrt(subset(df_lm, select = -mpg)),df_lm["mpg"])
model4 <- lm(mpg~., df_lm3)
(smry4 <- summary(model4))
## X^2
df_lm4 <- data.frame((subset(df_lm, select = -mpg))^2,df_lm["mpg"])
model5 <- lm(mpg~., df_lm4)
(smry5 <- summary(model5))
str(Carseats)
car_lm <- lm(Sales~Price+Urban+US,Carseats)
summary(car_lm)
car_lm <- lm(Sales~Price+Urban+US,Carseats)
(smry(summary(car_lm)))
car_lm <- lm(Sales~Price+Urban+US,Carseats)
(smry <- summary(car_lm)))
car_lm <- lm(Sales~Price+Urban+US,Carseats)
(smry <- summary(car_lm))
smry$coefficients
smry$coefficients[[Estimate]]
smry$coefficients[["Estimate"]]
smry$coefficients["Estimate"]
car_lm$coefficients[["Price"]]
car_lm1 <- lm(Sales~Price+US,Carseats)
(smry1 <- summary(car_lm1))
smry$adj.r.squared
car_lm1$contrasts
confint(smry1)
confint(smry1,"Price")
confint(car_lm1)
confint(car_lm1,level=0.95)
